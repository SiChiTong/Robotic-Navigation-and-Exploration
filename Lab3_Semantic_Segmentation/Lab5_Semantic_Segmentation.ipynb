{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab5_Samantic_Segmentation_lab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VwfKhFfHF27m","colab_type":"text"},"source":["# Semantic Segmentation with PyTorch"]},{"cell_type":"markdown","metadata":{"id":"qGeguvkAGNlw","colab_type":"text"},"source":["Mount google drive to colab."]},{"cell_type":"code","metadata":{"id":"RHc49hWDOJKw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f0997690-0317-47c0-c3b4-7eafcee2b296","executionInfo":{"status":"ok","timestamp":1590204711802,"user_tz":-480,"elapsed":693,"user":{"displayName":"蔡勁家","photoUrl":"","userId":"11384490137617593008"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eWNmktpFOddS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"212e39d1-1e88-4be3-b5fe-307870eb85de","executionInfo":{"status":"ok","timestamp":1590204735067,"user_tz":-480,"elapsed":23948,"user":{"displayName":"蔡勁家","photoUrl":"","userId":"11384490137617593008"}}},"source":["# if you mount Google drive correctly, the following commands should be able to executed correctly\n","!ls /content/drive/\n","%cd \"/content/drive/My Drive/CamVid\"\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["'My Drive'\n","/content/drive/.shortcut-targets-by-id/1K8kys7gWfI-As3lCz6O4Y6ETdn_OVTd_/CamVid\n","result_comparision  train  trainannot  train.csv  val  valannot  val.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jly0ouf9eNOQ","colab_type":"text"},"source":["Import neccessary libraties and set parameters."]},{"cell_type":"code","metadata":{"id":"Qzie3tp6QThn","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models\n","\n","import numpy as np\n","import time\n","import os\n","\n","from PIL import Image\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyGTWuMwngPV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"0fbd3515-04e7-40b6-eb78-9aa497b9f966","executionInfo":{"status":"ok","timestamp":1590204735489,"user_tz":-480,"elapsed":24351,"user":{"displayName":"蔡勁家","photoUrl":"","userId":"11384490137617593008"}}},"source":["# dataset path\n","root_dir   = \"/content/drive/My Drive/CamVid/\"\n","train_file = os.path.join(root_dir, \"train.csv\")\n","val_file   = os.path.join(root_dir, \"val.csv\")\n","\n","print(\"training csv exits:{}\".format(os.path.exists(train_file)))\n","print(\"validation csv exits:{}\".format(os.path.exists(val_file)))\n","\n","# Create folder to store training results.\n","val_dir = \"/content/drive/My Drive/segmentation_output/\"\n","if os.path.isdir(val_dir) == False:\n","   os.mkdir(val_dir)\n","\n","# Parameters\n","num_class = 11 # 32 for original CamVid\n","input_h, input_w = 256, 256\n","batch_size = 16\n","epochs = 40\n","lr = 1e-4\n","use_gpu = torch.cuda.is_available()\n","\n","# index for validation images\n","global_index = 0\n","\n","# pixel accuracy and mIOU list \n","pixel_acc_list = []\n","mIOU_list = []"],"execution_count":4,"outputs":[{"output_type":"stream","text":["training csv exits:True\n","validation csv exits:True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nphF6DjpeZVB","colab_type":"text"},"source":["## CamVid Dataset"]},{"cell_type":"code","metadata":{"id":"HEgjfY74izJR","colab_type":"code","colab":{}},"source":["class CamVidDataset(Dataset):\n","    def __init__(self, csv_file, n_class=num_class, flip_rate=0.5, rand_crop=True):\n","        self.data = pd.read_csv(csv_file)\n","        self.n_class = n_class\n","        self.new_h = input_h\n","        self.new_w = input_w\n","        self.flip_rate = flip_rate  \n","        self.rand_crop = rand_crop\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # open image data\n","        img_name   = self.data.iloc[idx, 0]                \n","        img_name = root_dir  + img_name                        \n","        img = Image.open(img_name).convert('RGB')\n","        \n","        # open label data\n","        label_name = self.data.iloc[idx, 1]        \n","        label_name = root_dir  + label_name                       \n","        label_image = Image.open(label_name)\n","        \n","        # crop images and labels\n","        w, h = img.size\n","        if self.rand_crop:            \n","            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n","            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n","        else:            \n","            A_x_offset = int((w - self.new_w)/2)\n","            A_y_offset = int((h - self.new_h)/2)\n","       \n","        img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","        label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","\n","        # flip images and labels\n","        img = np.transpose(img, (2, 0, 1)) / 255.\n","        label = np.asarray(label_image)\n","        if np.random.sample() < self.flip_rate:\n","            img = np.fliplr(img)\n","            label = np.fliplr(label)\n","\n","        # create tensor\n","        img = torch.from_numpy(img.copy()).float()\n","        label = torch.from_numpy(label.copy()).long()\n","\n","        # create one-hot encoding tensor\n","        h, w = label.size()\n","        target = torch.zeros(self.n_class, h, w)\n","        for c in range(self.n_class):\n","            target[c][label == c] = 1\n","\n","        sample = {'X': img, 'Y': target, 'l': label}\n","        return sample\n","\n","# Load dataset\n","train_data = CamVidDataset(csv_file=train_file, flip_rate=0.5, rand_crop=True)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n","val_data = CamVidDataset(csv_file=val_file, flip_rate=0, rand_crop=False)\n","val_loader = DataLoader(val_data, batch_size=1, num_workers=8)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKvpt9GTefaL","colab_type":"text"},"source":["## Network Model\n","### VGG16 Feature Extractor (pretrained)"]},{"cell_type":"code","metadata":{"id":"CUfJoO8e-rrB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":578},"outputId":"c99078b8-7d2c-4b30-dd26-ad6628d9583d","executionInfo":{"status":"ok","timestamp":1590204739623,"user_tz":-480,"elapsed":28468,"user":{"displayName":"蔡勁家","photoUrl":"","userId":"11384490137617593008"}}},"source":["class Vgg16(nn.Module):\n","    def __init__(self, pretrained = True):\n","        super(Vgg16, self).__init__()\n","        self.vggnet = models.vgg16(pretrained)\n","        del(self.vggnet.classifier) # Remove fully connected layer to save memory.\n","        features = list(self.vggnet.features)\n","        self.layers = nn.ModuleList(features).eval() \n","        \n","    def forward(self, x):\n","        results = []\n","        for ii,model in enumerate(self.layers):\n","            x = model(x)\n","            if ii in [3,8,15,22,29]:\n","                results.append(x) #(64,256,256),(128,128,128),(256,64,64),(512,32,32),(512,16,16)\n","        return results\n","\n","vgg_model = Vgg16()\n","vgg_model = vgg_model.cuda()\n","print(vgg_model.layers)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["ModuleList(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU(inplace=True)\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU(inplace=True)\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU(inplace=True)\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU(inplace=True)\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (11): ReLU(inplace=True)\n","  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU(inplace=True)\n","  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): ReLU(inplace=True)\n","  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (18): ReLU(inplace=True)\n","  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (20): ReLU(inplace=True)\n","  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (22): ReLU(inplace=True)\n","  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (25): ReLU(inplace=True)\n","  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (27): ReLU(inplace=True)\n","  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (29): ReLU(inplace=True)\n","  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"10fl6vwtE2Dz","colab_type":"text"},"source":["### Encoder-Decoder"]},{"cell_type":"code","metadata":{"id":"CVmJVvvj1W9H","colab_type":"code","colab":{}},"source":["class DeConv2d(nn.Module):\n","    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, dilation):\n","        super().__init__()\n","        #####################################\n","        #TODO\n","        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n","        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n","        #####################################\n","    \n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        output = self.up(x)\n","        output = self.conv(output)\n","        #####################################\n","        return output\n","\n","class EncoderDecoder(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        output = self.pretrained_net(x)[4]\n","\n","        output = self.deconv1(output)\n","        output = self.relu(output)\n","        output = self.bn1(output)\n","        output = self.deconv2(output)\n","        output = self.relu(output)\n","        output = self.bn2(output)\n","        output = self.deconv3(output)\n","        output = self.relu(output)\n","        output = self.bn3(output)\n","        output = self.deconv4(output)\n","        output = self.relu(output)\n","        output = self.bn4(output)\n","\n","        output = self.classifier(output)\n","        #####################################\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-J1MWQfewD9","colab_type":"text"},"source":["### Fully Convolution Network (FCN)\n"]},{"cell_type":"code","metadata":{"id":"MjZ4-8X1EzFv","colab_type":"code","colab":{}},"source":["class FCN(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        #####################################\n","        #TODO\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","        #####################################\n","\n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        output = self.pretrained_net(x)\n","\n","        x5 = output[4]\n","        x4 = output[3]\n","        x3 = output[2]\n","\n","        output = self.deconv1(x5)\n","        output = self.relu(output)\n","        output = self.bn1(output + x4)\n","        output = self.deconv2(output)\n","        output = self.relu(output)\n","        output = self.bn2(output + x3)\n","        output = self.deconv3(output)\n","        output = self.relu(output)\n","        output = self.bn3(output)\n","        output = self.deconv4(output)\n","        output = self.relu(output)\n","        output = self.bn4(output)\n","\n","        output = self.classifier(output)\n","        #####################################\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5xIH1GffFXP","colab_type":"text"},"source":["### U-Net"]},{"cell_type":"code","metadata":{"id":"ZbAKDtkwJQH7","colab_type":"code","colab":{}},"source":["class UNet(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        #####################################\n","        #TODO\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv1_1 = nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv1_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv2_1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv2_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv3_1 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv3_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv4_1 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.conv4_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","        #####################################\n","    \n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        output = self.pretrained_net(x)\n","\n","        x5 = output[4]\n","        x4 = output[3]\n","        x3 = output[2]\n","        x2 = output[1]\n","        x1 = output[0]\n","\n","        output = self.deconv1(x5)\n","        cat1 = torch.cat([output,x4], dim=1)\n","        output = self.conv1_1(cat1)\n","        output = self.bn1(output)\n","        output = self.relu(output)\n","        output = self.conv1_2(output)\n","        output = self.bn1(output)\n","        output = self.relu(output)\n","\n","        output = self.deconv2(output)\n","        cat2 = torch.cat([output,x3], dim=1)\n","        output = self.conv2_1(cat2)\n","        output = self.bn2(output)\n","        output = self.relu(output)\n","        output = self.conv2_2(output)\n","        output = self.bn2(output)\n","        output = self.relu(output)\n","\n","        output = self.deconv3(output)\n","        cat3 = torch.cat([output,x2], dim=1)\n","        output = self.conv3_1(cat3)\n","        output = self.bn3(output)\n","        output = self.relu(output)\n","        output = self.conv3_2(output)\n","        output = self.bn3(output)\n","        output = self.relu(output)\n","\n","        output = self.deconv4(output)\n","        cat4 = torch.cat([output,x1], dim=1)\n","        output = self.conv4_1(cat4)\n","        output = self.bn4(output)\n","        output = self.relu(output)\n","        output = self.conv4_2(output)\n","        output = self.bn4(output)\n","        output = self.relu(output)\n","\n","        output = self.classifier(output)\n","        #####################################\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwISqBr0yMTQ","colab_type":"text"},"source":["### PSPNet"]},{"cell_type":"code","metadata":{"id":"ttK5Y9AuyJ7y","colab_type":"code","colab":{}},"source":["class PSPNet(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        #####################################\n","        #TODO\n","\n","        #### Pyramid Pooling Moudule\n","        self.ppm_size = (16, 16)\n","        self.ppm_channel = 512\n","        self.ppm_psize = [1, 2, 3, 6]\n","        \n","        self.ppm_pool, self.ppm_conv, self.ppm_up = [], [], []\n","        for psize in self.ppm_psize:\n","            self.ppm_pool.append(nn.AdaptiveAvgPool2d((psize,psize)))\n","            self.ppm_conv.append(nn.Conv2d(int(self.ppm_channel), int(self.ppm_channel/len(self.ppm_psize)), kernel_size=1))\n","            self.ppm_up.append(nn.Upsample(size=self.ppm_size, mode='bilinear', align_corners=True))\n","        \n","        self.ppm_pool = nn.ModuleList(self.ppm_pool)\n","        self.ppm_conv = nn.ModuleList(self.ppm_conv)\n","        self.ppm_up = nn.ModuleList(self.ppm_up)\n","        ####\n","\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.deconv1 = DeConv2d(1024, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","        #####################################\n","\n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        output = self.pretrained_net(x)\n","\n","        x5 = output[4]\n","        x4 = output[3]\n","        x3 = output[2]\n","\n","        ppm_list = [x5]\n","        for i in range(len(self.ppm_psize)):\n","            output = self.ppm_pool[i](x5)\n","            output = self.ppm_conv[i](output)\n","            output = self.ppm_up[i](self.relu(output))\n","            ppm_list.append(output)\n","        output = torch.cat(ppm_list, 1)\n","\n","        output = self.deconv1(output)\n","        output = self.relu(output)\n","        output = self.bn1(output + x4)\n","        output = self.deconv2(output)\n","        output = self.relu(output)\n","        output = self.bn2(output + x3)\n","        output = self.deconv3(output)\n","        output = self.relu(output)\n","        output = self.bn3(output)\n","        output = self.deconv4(output)\n","        output = self.relu(output)\n","        output = self.bn4(output)\n","\n","        output = self.classifier(output)\n","        #####################################\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjcje1cPfIYs","colab_type":"text"},"source":["Construct models."]},{"cell_type":"code","metadata":{"id":"oj3Ng3mi1deU","colab_type":"code","colab":{}},"source":["#seg_model = EncoderDecoder(pretrained_net=vgg_model, n_class=num_class)\n","#seg_model = FCN(pretrained_net=vgg_model, n_class=num_class)\n","#seg_model = UNet(pretrained_net=vgg_model, n_class=num_class)\n","seg_model = PSPNet(pretrained_net=vgg_model, n_class=num_class)\n","\n","seg_model = seg_model.cuda()\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(seg_model.parameters(), lr=lr)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9beJVr7yfNKT","colab_type":"text"},"source":["## Training and Validation"]},{"cell_type":"code","metadata":{"id":"pQtApd8vLCa8","colab_type":"code","colab":{}},"source":["def train():\n","    for epoch in range(epochs):\n","        ts = time.time()\n","        for iter, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            inputs = torch.FloatTensor(batch['X'])\n","            labels = torch.FloatTensor(batch['Y'])\n","            if use_gpu:\n","              inputs = inputs.cuda()\n","              labels = labels.cuda()\n","\n","            outputs = seg_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if iter % 10 == 0:\n","                print(\"epoch:{:2}, iter:{:2}, loss: {:.4f}\".format(epoch, iter, loss.data.item()))\n","        \n","        print(\"Finish epoch:{:2}, time elapsed: {:.4f}\".format(epoch, time.time() - ts))\n","        validate()\n","        print(\"========================================\")\n","        \n","    highest_pixel_acc = max(pixel_acc_list)\n","    highest_mIOU = max(mIOU_list)        \n","    \n","    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n","    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n","    \n","    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n","    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DtvW9ZqJnmLE","colab_type":"code","colab":{}},"source":["def validate():\n","    seg_model.eval()\n","    total_ious = []\n","    pixel_accs = []\n","                    \n","    for iter, batch in enumerate(val_loader): ## batch is 1 in this case\n","        inputs = torch.FloatTensor(batch['X'])\n","        if use_gpu:\n","          inputs = inputs.cuda()      \n","\n","        output = seg_model(inputs)                                \n","        \n","        # only save the 1st image for comparison\n","        if iter == 0:\n","            # generate images\n","            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n","            image = images[0,:,:]        \n","            save_result(batch['X'], image)\n","                            \n","        output = output.data.cpu().numpy()\n","\n","        N, _, h, w = output.shape                \n","        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n","        target = batch['l'].cpu().numpy().reshape(N, h, w)\n","\n","        for p, t in zip(pred, target):\n","            total_ious.append(iou(p, t))\n","            pixel_accs.append(pixel_acc(p, t))\n","\n","    # Calculate average IoU\n","    total_ious = np.array(total_ious).T  # n_class * val_len\n","    ious = np.nanmean(total_ious, axis=1)\n","    pixel_accs = np.array(pixel_accs).mean()\n","    print(\"pix_acc: {:.4f}, meanIoU: {:.4f}\".format(pixel_accs, np.nanmean(ious)))\n","    \n","    global pixel_acc_list\n","    global mIOU_list\n","    \n","    pixel_acc_list.append(pixel_accs)\n","    mIOU_list.append(np.nanmean(ious))\n","\n","# Calculates class intersections over unions\n","def iou(pred, target):\n","    ious = []\n","    for cls in range(num_class):\n","        pred_inds = pred == cls\n","        target_inds = target == cls\n","        intersection = pred_inds[target_inds].sum()\n","        union = pred_inds.sum() + target_inds.sum() - intersection\n","        if union == 0:\n","            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\n","        else:\n","            ious.append(float(intersection) / max(union, 1))\n","    return ious\n","\n","def pixel_acc(pred, target):\n","    correct = (pred == target).sum()\n","    total   = (target == target).sum()\n","    return correct / total     \n","\n","def save_result(input_np, output_np):\n","    global global_index\n","    \n","    original_im_RGB = np.zeros((256,256,3))    \n","    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n","    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n","    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] \n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] \n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] \n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n","    \n","    im_seg_RGB = np.zeros((256,256,3))\n","\n","    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n","    for i in range(256):\n","        for j in range(256):\n","            if output_np[i,j] == 0:\n","                im_seg_RGB[i,j,:] = [128, 128, 128]\n","            elif output_np[i,j] == 1:  \n","                im_seg_RGB[i,j,:] = [128, 0, 0]\n","            elif output_np[i,j] == 2:  \n","                im_seg_RGB[i,j,:] = [192, 192, 128]    \n","            elif output_np[i,j] == 3:  \n","                im_seg_RGB[i,j,:] = [128, 64, 128]    \n","            elif output_np[i,j] == 4:  \n","                im_seg_RGB[i,j,:] = [0, 0, 192]    \n","            elif output_np[i,j] == 5:  \n","                im_seg_RGB[i,j,:] = [128, 128, 0]    \n","            elif output_np[i,j] == 6:  \n","                im_seg_RGB[i,j,:] = [192, 128, 128]    \n","            elif output_np[i,j] == 7:  \n","                im_seg_RGB[i,j,:] = [64, 64, 128]    \n","            elif output_np[i,j] == 8:  \n","                im_seg_RGB[i,j,:] = [64, 0, 128]    \n","            elif output_np[i,j] == 9:  \n","                im_seg_RGB[i,j,:] = [64, 64, 0]    \n","            elif output_np[i,j] == 10:  \n","                im_seg_RGB[i,j,:] = [0, 128, 192]    \n","                    \n","    # horizontally stack original image and its corresponding segmentation results     \n","    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n","    new_im = Image.fromarray(np.uint8(hstack_image))\n","    file_name = val_dir + str(global_index).zfill(3) + '.jpg'\n","    global_index = global_index + 1\n","    new_im.save(file_name)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q80RO6M5JmE5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"78e35f12-3795-4533-c7db-9670fccb4953","executionInfo":{"status":"ok","timestamp":1590205254375,"user_tz":-480,"elapsed":543156,"user":{"displayName":"蔡勁家","photoUrl":"","userId":"11384490137617593008"}}},"source":["# perform training and validation\n","train()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["epoch: 0, iter: 0, loss: 0.7392\n","epoch: 0, iter:10, loss: 0.6663\n","epoch: 0, iter:20, loss: 0.6598\n","Finish epoch: 0, time elapsed: 9.5973\n","pix_acc: 0.7540, meanIoU: 0.3096\n","========================================\n","epoch: 1, iter: 0, loss: 0.6291\n","epoch: 1, iter:10, loss: 0.1905\n","epoch: 1, iter:20, loss: 0.1597\n","Finish epoch: 1, time elapsed: 9.6051\n","pix_acc: 0.7548, meanIoU: 0.2860\n","========================================\n","epoch: 2, iter: 0, loss: 0.1578\n","epoch: 2, iter:10, loss: 0.1424\n","epoch: 2, iter:20, loss: 0.1329\n","Finish epoch: 2, time elapsed: 9.5471\n","pix_acc: 0.7587, meanIoU: 0.2979\n","========================================\n","epoch: 3, iter: 0, loss: 0.1248\n","epoch: 3, iter:10, loss: 0.1317\n","epoch: 3, iter:20, loss: 0.1381\n","Finish epoch: 3, time elapsed: 9.6141\n","pix_acc: 0.7667, meanIoU: 0.2994\n","========================================\n","epoch: 4, iter: 0, loss: 0.1030\n","epoch: 4, iter:10, loss: 0.1079\n","epoch: 4, iter:20, loss: 0.1211\n","Finish epoch: 4, time elapsed: 9.6599\n","pix_acc: 0.8150, meanIoU: 0.3697\n","========================================\n","epoch: 5, iter: 0, loss: 0.1067\n","epoch: 5, iter:10, loss: 0.1138\n","epoch: 5, iter:20, loss: 0.1547\n","Finish epoch: 5, time elapsed: 9.6426\n","pix_acc: 0.8253, meanIoU: 0.3807\n","========================================\n","epoch: 6, iter: 0, loss: 0.1146\n","epoch: 6, iter:10, loss: 0.1031\n","epoch: 6, iter:20, loss: 0.1119\n","Finish epoch: 6, time elapsed: 9.7452\n","pix_acc: 0.8308, meanIoU: 0.3887\n","========================================\n","epoch: 7, iter: 0, loss: 0.0969\n","epoch: 7, iter:10, loss: 0.1057\n","epoch: 7, iter:20, loss: 0.1160\n","Finish epoch: 7, time elapsed: 9.6952\n","pix_acc: 0.8393, meanIoU: 0.4009\n","========================================\n","epoch: 8, iter: 0, loss: 0.0918\n","epoch: 8, iter:10, loss: 0.1059\n","epoch: 8, iter:20, loss: 0.1072\n","Finish epoch: 8, time elapsed: 9.6301\n","pix_acc: 0.8357, meanIoU: 0.4005\n","========================================\n","epoch: 9, iter: 0, loss: 0.0808\n","epoch: 9, iter:10, loss: 0.1130\n","epoch: 9, iter:20, loss: 0.1069\n","Finish epoch: 9, time elapsed: 9.6817\n","pix_acc: 0.8430, meanIoU: 0.4168\n","========================================\n","epoch:10, iter: 0, loss: 0.0807\n","epoch:10, iter:10, loss: 0.0888\n","epoch:10, iter:20, loss: 0.1046\n","Finish epoch:10, time elapsed: 9.6465\n","pix_acc: 0.8337, meanIoU: 0.4171\n","========================================\n","epoch:11, iter: 0, loss: 0.0926\n","epoch:11, iter:10, loss: 0.0889\n","epoch:11, iter:20, loss: 0.1018\n","Finish epoch:11, time elapsed: 9.7222\n","pix_acc: 0.8493, meanIoU: 0.4521\n","========================================\n","epoch:12, iter: 0, loss: 0.0739\n","epoch:12, iter:10, loss: 0.1003\n","epoch:12, iter:20, loss: 0.1015\n","Finish epoch:12, time elapsed: 9.6660\n","pix_acc: 0.8379, meanIoU: 0.4312\n","========================================\n","epoch:13, iter: 0, loss: 0.0882\n","epoch:13, iter:10, loss: 0.0915\n","epoch:13, iter:20, loss: 0.1093\n","Finish epoch:13, time elapsed: 9.7713\n","pix_acc: 0.8283, meanIoU: 0.4362\n","========================================\n","epoch:14, iter: 0, loss: 0.0841\n","epoch:14, iter:10, loss: 0.0877\n","epoch:14, iter:20, loss: 0.0776\n","Finish epoch:14, time elapsed: 9.6383\n","pix_acc: 0.8658, meanIoU: 0.4973\n","========================================\n","epoch:15, iter: 0, loss: 0.0772\n","epoch:15, iter:10, loss: 0.0963\n","epoch:15, iter:20, loss: 0.0949\n","Finish epoch:15, time elapsed: 9.6312\n","pix_acc: 0.8586, meanIoU: 0.4932\n","========================================\n","epoch:16, iter: 0, loss: 0.0696\n","epoch:16, iter:10, loss: 0.0942\n","epoch:16, iter:20, loss: 0.1029\n","Finish epoch:16, time elapsed: 9.6782\n","pix_acc: 0.8620, meanIoU: 0.5025\n","========================================\n","epoch:17, iter: 0, loss: 0.0729\n","epoch:17, iter:10, loss: 0.0850\n","epoch:17, iter:20, loss: 0.0979\n","Finish epoch:17, time elapsed: 9.7014\n","pix_acc: 0.8613, meanIoU: 0.5096\n","========================================\n","epoch:18, iter: 0, loss: 0.0723\n","epoch:18, iter:10, loss: 0.0788\n","epoch:18, iter:20, loss: 0.0946\n","Finish epoch:18, time elapsed: 9.6405\n","pix_acc: 0.8712, meanIoU: 0.5268\n","========================================\n","epoch:19, iter: 0, loss: 0.0756\n","epoch:19, iter:10, loss: 0.0814\n","epoch:19, iter:20, loss: 0.0879\n","Finish epoch:19, time elapsed: 9.7968\n","pix_acc: 0.8662, meanIoU: 0.5144\n","========================================\n","epoch:20, iter: 0, loss: 0.0727\n","epoch:20, iter:10, loss: 0.0867\n","epoch:20, iter:20, loss: 0.0883\n","Finish epoch:20, time elapsed: 9.6314\n","pix_acc: 0.8800, meanIoU: 0.5629\n","========================================\n","epoch:21, iter: 0, loss: 0.0744\n","epoch:21, iter:10, loss: 0.0801\n","epoch:21, iter:20, loss: 0.0906\n","Finish epoch:21, time elapsed: 9.7833\n","pix_acc: 0.8758, meanIoU: 0.5447\n","========================================\n","epoch:22, iter: 0, loss: 0.0860\n","epoch:22, iter:10, loss: 0.0792\n","epoch:22, iter:20, loss: 0.0974\n","Finish epoch:22, time elapsed: 9.7099\n","pix_acc: 0.8735, meanIoU: 0.5412\n","========================================\n","epoch:23, iter: 0, loss: 0.0770\n","epoch:23, iter:10, loss: 0.0771\n","epoch:23, iter:20, loss: 0.0922\n","Finish epoch:23, time elapsed: 9.5515\n","pix_acc: 0.8704, meanIoU: 0.5482\n","========================================\n","epoch:24, iter: 0, loss: 0.0733\n","epoch:24, iter:10, loss: 0.0862\n","epoch:24, iter:20, loss: 0.0841\n","Finish epoch:24, time elapsed: 9.6652\n","pix_acc: 0.8815, meanIoU: 0.5715\n","========================================\n","epoch:25, iter: 0, loss: 0.0676\n","epoch:25, iter:10, loss: 0.0747\n","epoch:25, iter:20, loss: 0.0880\n","Finish epoch:25, time elapsed: 9.7585\n","pix_acc: 0.8862, meanIoU: 0.5823\n","========================================\n","epoch:26, iter: 0, loss: 0.0625\n","epoch:26, iter:10, loss: 0.0672\n","epoch:26, iter:20, loss: 0.0785\n","Finish epoch:26, time elapsed: 9.5744\n","pix_acc: 0.8869, meanIoU: 0.5759\n","========================================\n","epoch:27, iter: 0, loss: 0.0587\n","epoch:27, iter:10, loss: 0.0794\n","epoch:27, iter:20, loss: 0.0832\n","Finish epoch:27, time elapsed: 9.7181\n","pix_acc: 0.8847, meanIoU: 0.5751\n","========================================\n","epoch:28, iter: 0, loss: 0.0561\n","epoch:28, iter:10, loss: 0.0758\n","epoch:28, iter:20, loss: 0.0789\n","Finish epoch:28, time elapsed: 9.6809\n","pix_acc: 0.8825, meanIoU: 0.5593\n","========================================\n","epoch:29, iter: 0, loss: 0.0716\n","epoch:29, iter:10, loss: 0.0727\n","epoch:29, iter:20, loss: 0.0757\n","Finish epoch:29, time elapsed: 9.7009\n","pix_acc: 0.8684, meanIoU: 0.5476\n","========================================\n","epoch:30, iter: 0, loss: 0.0701\n","epoch:30, iter:10, loss: 0.0703\n","epoch:30, iter:20, loss: 0.0761\n","Finish epoch:30, time elapsed: 9.7906\n","pix_acc: 0.8923, meanIoU: 0.5988\n","========================================\n","epoch:31, iter: 0, loss: 0.0655\n","epoch:31, iter:10, loss: 0.0664\n","epoch:31, iter:20, loss: 0.0810\n","Finish epoch:31, time elapsed: 9.7952\n","pix_acc: 0.8857, meanIoU: 0.5722\n","========================================\n","epoch:32, iter: 0, loss: 0.0611\n","epoch:32, iter:10, loss: 0.0815\n","epoch:32, iter:20, loss: 0.0835\n","Finish epoch:32, time elapsed: 9.7682\n","pix_acc: 0.8945, meanIoU: 0.6036\n","========================================\n","epoch:33, iter: 0, loss: 0.0608\n","epoch:33, iter:10, loss: 0.0674\n","epoch:33, iter:20, loss: 0.0803\n","Finish epoch:33, time elapsed: 9.8785\n","pix_acc: 0.8939, meanIoU: 0.5974\n","========================================\n","epoch:34, iter: 0, loss: 0.0595\n","epoch:34, iter:10, loss: 0.0693\n","epoch:34, iter:20, loss: 0.0796\n","Finish epoch:34, time elapsed: 9.6907\n","pix_acc: 0.8781, meanIoU: 0.5521\n","========================================\n","epoch:35, iter: 0, loss: 0.0613\n","epoch:35, iter:10, loss: 0.0655\n","epoch:35, iter:20, loss: 0.0723\n","Finish epoch:35, time elapsed: 9.8419\n","pix_acc: 0.8964, meanIoU: 0.6017\n","========================================\n","epoch:36, iter: 0, loss: 0.0645\n","epoch:36, iter:10, loss: 0.0600\n","epoch:36, iter:20, loss: 0.0759\n","Finish epoch:36, time elapsed: 9.6250\n","pix_acc: 0.8821, meanIoU: 0.5811\n","========================================\n","epoch:37, iter: 0, loss: 0.0645\n","epoch:37, iter:10, loss: 0.0620\n","epoch:37, iter:20, loss: 0.0797\n","Finish epoch:37, time elapsed: 9.6635\n","pix_acc: 0.9007, meanIoU: 0.6072\n","========================================\n","epoch:38, iter: 0, loss: 0.0602\n","epoch:38, iter:10, loss: 0.0707\n","epoch:38, iter:20, loss: 0.0765\n","Finish epoch:38, time elapsed: 9.8269\n","pix_acc: 0.8902, meanIoU: 0.5905\n","========================================\n","epoch:39, iter: 0, loss: 0.0658\n","epoch:39, iter:10, loss: 0.0673\n","epoch:39, iter:20, loss: 0.0785\n","Finish epoch:39, time elapsed: 9.6094\n","pix_acc: 0.8985, meanIoU: 0.5961\n","========================================\n","The highest mIOU is 0.6072422959956547 and is achieved at epoch-37\n","The highest pixel accuracy  is 0.900675048828125 and is achieved at epoch-37\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GSPf3l3Dr7XZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}